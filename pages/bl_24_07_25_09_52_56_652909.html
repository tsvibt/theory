
   <!DOCTYPE html>
   <html lang="en">
   <head>
       <meta charset="UTF-8">
       <meta name="viewport" content="width=device-width, initial-scale=1.0">
       <title>Algebraicness</title>
       <link href="../includes/styles.css" rel="stylesheet">
   </head>
   <body>
          <script src="../includes/script.js"></script>
          <p>There's a dimension of task-sets that's something like: how much is it the case that solving tasks like this basically boils down to "crunching the numbers"? </p>
<p>We could call this "combinatoricness" or "algebraicness". Algebraic things are soulless, calculative. More to the point, compared to more structure-rich tasks, it's less the case that being a mind implies being good at algebraic tasks, or vice versa.</p>
<p>Examples:</p>
<ul>
<li>Small-world games tend to be algebraic. E.g. chess, Go, etc. Think of a <a href="https://en.wikipedia.org/wiki/Zachtronics">Zachtronics</a> game like SpaceChem. Or tetris. </li>
</ul>
<ul>
<li>Similarly, a lot of problems in number theory or analysis have this quality. Think of doing a complex integral that involves applying a number of "tricks", or generally doing complicated algebra. Constructions in axiomatic geometry also have this quality. I think the IMO problems that <a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/">this AI solved</a> have this quality in contrast to at least problem 5, though not sure. (The boundary here is much more jagged than just subareas of math, though.)</li>
</ul>
<ul>
<li>Fairly extremely algebraic would be computing a complicated chaotic system; you just have to do all the detailed computations. </li>
</ul>
<ul>
<li>Among the most extremely algebraic would be average-case hard computations. E.g., reversing a <a href="https://en.wikipedia.org/wiki/One-way_function">one-way function</a> with non-tiny probability absolutely requires large amounts of compute. </li>
</ul>
<ul>
<li>It's definitely <em>not</em> the case that "AI only exceeds human capability in very algebraic task-sets". LLMs and stable diffusion image generation both seem like they exceed humans at some aspects of their respective task-sets that are not very algebraic, though everything is a mix to some extent. But a reverse statement might be true: If a task-set has a high degree of algebraicness, and an AI can pass a minimum threshold of <a href="https://tsvibt.blogspot.com/2023/03/explicitness.html#possession">possessing</a> the structure to unlock the compute -&gt; optimization pipeline, then AI exceeds humans at that task-set. </li>
</ul>
<ul>
<li>Most normal tasks humans do aren't very algebraic.</li>
</ul>
<p>Humans tend to find it fun when there's a continuum of combinatorics/algebra in a domain. In chess, very crudely speaking, you could look one move ahead, two moves ahead, etc. (That's not really how it works, but there's a similar spirit that does hold true. Stronger players will tend to deal with longer, more complex, more contingent, more counterintuitive combinations. Even Karpov would, I assume without knowing, be playing strategically/positionally in response to an environment with such calculating opponents, tuned to shut down such tactics.) </p>
<p>We can ask different things. We can ask "how much <a href="https://tsvibt.blogspot.com/2023/03/explicitness.html">explicit</a> <a href="https://tsvibt.blogspot.com/2022/08/structure-creativity-and-novelty.html">structure</a> is there to be recognized in the world of this task-set"; this could range from 0 up to the whole cosmos. We can also ask "how much explicit structure is there, relative to the less <a href="https://tsvibt.blogspot.com/2022/08/the-thingness-of-things.html">thing</a>-like combinatorics". That's an ambiguous question, but for example we could be asking "if there's an agent that performs at such-and-such level when predicting / manipulating / planning / designing stuff in this area, what would tend to be the ratio of explicit-structure to combinatorics?". A fuller analysis would tease these things apart more.</p>
<p>See <a href="https://en.wikipedia.org/wiki/Sophistication_(complexity_theory)">sophistication</a>.</p>
   </body>
   </html>
   